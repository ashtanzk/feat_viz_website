<!DOCTYPE HTML>
<!--
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Let's try manipulating some images!</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Header -->
			<header id="header">
				<a href="index.html" class="title">Convolutional Neural Networks</a>
				<nav>
					<ul>
						<li><a href="index.html">Home</a></li>
					</ul>
				</nav>
			</header>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<section id="main" class="wrapper">
						<div class="inner">
							<h1 class="major">Let's try manipulating some images!</h1>
							<span class="image fit"><img src="images/pic04.jpg" alt="" /></span>
							<p>Now that we know how CNN models classify images through feature map activations, the CNN is not such a black box after all.</p>
							<p>We have also played with pixels to generate an image which highly activates a particular feature map, letting us visualise how that feature map looks like.</p>
							<p>Now we can combine this newly gained knowledge to try and manipulate an existing image.</p>
							<h3>
								Why do we need to do this?
							</h3>
							<p>We will be performing pixel manipulation to both demonstrate how images can be manipulated, as well as to show the possibilities of adversarial attacks on these models.</p>
							<p>From the previous sections, we have learnt that CNN models make use of pixel values to "recognise" features based on the activations of that particular feature map.</p>
							<p>While this exercise is a fun exploration into how we can trick the model into misclassifying images, it also serves to give us an insight into possible adversarial attacks.</p>
							<hr class="divider">
							<h3>
								Before we proceed
							</h3>
							<p>For the following sections, we will be using activation plots to show which filters are being activated by the model.</p>
							<div class="img-showcase">
								<figure>
									<img src="images/activation-plot.png" style="width:40%; background-color: white; padding:0;">
									<figcaption>Activation plot</figcaption>
								</figure>
							</div>
							<p>This plot is an activation plot. The y-axis represents the mean activation, while the x-axis represents the various filters present in the last convolutional layer of the model.</p>
							<p>From this plot, we are able to tell that the input image resulted in both filters 90 and 309 having a relatively high mean activation. That essentially means that the features present in those two filters are detected by the model from its convolutional layers.</p>
							<p>If we know that filter 90 is the filter with the pattern of cat ears, and filter 309 is the filter with the pattern of the cat fur, we can somewhat guess that the input image is quite close to a cat.</p>
							<hr class="divider">
							<h3>
								Fast Gradient Sign Method
							</h3>
							<p>For the image manipulation, we will be making use of the Fast Gradient Sign Method (FGSM), which is a form of adversarial attack on CNN models. This method works by generating a pertubation image whose pixel values are of the same direction as the gradient of the cost function with respect to the data. The noise is scaled by epsilon, which is usually constrained to be a small number via max norm.</p>
							<h3>
								Let us apply this
							</h3>
							<p>First, we will start off with this input image of a broccoli.</p>
							<div class="img-showcase">
								<figure>
									<img src="images/broccoli.jpg">
									<figcaption>Image of a broccoli</figcaption>
								</figure>
							</div>
							<p>Running this image through the CNN model, we can see that it is correctly classified as broccoli with 99% confidence.</p>
							<div class="img-showcase">
								<figure>
									<img src="images/broccoli-plot.png" style="background-color: white;">
									<figcaption>Activation plot for original broccoli</figcaption>
								</figure>
								<figure>
									<img src="images/broccoli-predictions.png" style="background-color: white;">
									<figcaption>Prediction scores for original broccoli</figcaption>
								</figure>
							</div>
							<p>Using the knowledge we have gained previously regarding optimising pixel values, we can now try to incorporate that here to minimise the class activation of the original broccoli image.</p>
							<p>We introduce a generated image by altering the pixel values, giving us this pertubation image.</p>
							<div class="img-showcase">
								<figure>
									<img src="images/broccoli-pertubation.jpg">
									<figcaption>Pertubation image</figcaption>
								</figure>
							</div>
							<p>We add this to the original image to generate the manipulated image of the broccoli.</p>
							<div class="img-showcase">
								<figure>
									<img src="images/broccoli.jpg">
									<figcaption>Image of a broccoli</figcaption>
								</figure>
								<figure>
									<img src="images/broccoli-pertubation.jpg">
									<figcaption>Pertubation image</figcaption>
								</figure>
								<figure>
									<img src="images/broccoli-adversarial.jpg">
									<figcaption>Manipulated broccoli</figcaption>
								</figure>
							</div>
							<p>With this newly manipulated image of the broccoli, we can run this through the same model to see the results.</p>
							<div class="img-showcase">
								<figure>
									<img src="images/broccoli-adversarial-plot.png" style="background-color: white;">
									<figcaption>Activation plot for manipulated broccoli</figcaption>
								</figure>
								<figure>
									<img src="images/broccoli-adversarial-predictions.png" style="background-color: white;">
									<figcaption>Prediction scores for manipulated broccoli</figcaption>
								</figure>
							</div>
							<p>The manipulated image of the broccoli is now classified as a sombrero with a confidence of 29%, meaning that the addition of the pertubation has altered the class of the image.</p>
							<p>To the human eye, the manipulated image still resembles a broccoli, with the addition of some form of distortion to the image. This distortion, which is attributed to the pertubation, is enough to activate other feature maps, changing the classification of the image. </p>


							<hr class="divider">
							
							<p>We will now run through the pixel manipulation on the image of the broccoli, showing the before and after images side by side for a better comparison.</p>
							<div class="img-showcase">
								<figure>
									<img src="images/broccoli.jpg">
									<figcaption>Image of a broccoli</figcaption>
								</figure>
								<figure>
									<img src="images/broccoli-adversarial.jpg">
									<figcaption>Manipulated broccoli</figcaption>
								</figure>
							</div>
							<div class="img-showcase">
								<figure>
									<img src="images/broccoli-plot.png" style="background-color: white;">
									<figcaption>Activation plot for original broccoli</figcaption>
								</figure>
								<figure>
									<img src="images/broccoli-adversarial-plot.png" style="background-color: white;">
									<figcaption>Activation plot for manipulated broccoli</figcaption>
								</figure>
							</div>
							<div class="img-showcase">
								<figure>
									<img src="images/broccoli-predictions.png" style="background-color: white;">
									<figcaption>Prediction scores for original broccoli</figcaption>
								</figure>
								<figure>
									<img src="images/broccoli-adversarial-predictions.png" style="background-color: white;">
									<figcaption>Prediction scores for manipulated broccoli</figcaption>
								</figure>
							</div>


							<!-- <ul class="actions">
								<li><a href="index.html#one" class="button">Back</a></li>
							</ul> -->
							<ul class="actions">
								<li><a href="cnn-explain.html" class="button">Previous</a></li>
								<li><a href="index.html#one" class="button">Home</a></li>
							</ul>
						</div>
					</section>

			</div>

		<!-- Footer -->
			<footer id="footer" class="wrapper alt">
				<div class="inner">
					<ul class="menu">
						<li>&copy; Untitled. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>