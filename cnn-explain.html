<!DOCTYPE HTML>
<!--
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Explainability of CNN model</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Header -->
			<header id="header">
				<a href="index.html" class="title">Convolutional Neural Networks</a>
				<nav>
					<ul>
						<li><a href="index.html">Home</a></li>
						<li><a href="index.html#one">CNN</a></li>
						<li><a href="index.html#two">About us</a></li>
					</ul>
				</nav>
			</header>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<section id="main" class="wrapper">
						<div class="inner">
							<h1 class="major">Explainability of CNN model</h1>
							<span class="image fit"><img src="images/cnn-banner.png" alt="" /></span>
							<p>
								As mentioned previously, based on the features that have been extracted by the convolutional layers, classification of the image will then take place accordingly.
							</p>
							<p>
								We call this as having certain highly activated feature maps that correspond to that particular class.
							</p>
							<h3>
								What does that mean?
							</h3>
							<p>
								These feature maps are learned by the model during training, and each map is supposed to extract a certain feature given the input image. There are many feature maps found at each convolutional layer, and this is dependent on the configuration of the CNN model.
							</p>
							<p>
								For example, we would expect that an image of a building with vaulted ceilings would have highly activated feature maps corresponding to the arched structures. 
							</p>
							<div class="img-showcase">
								<figure>
									<img src="images/feature-map-illustration-white.png" style="width:70%;">
									<figcaption>Examples of feature maps from differing convolutional layers</figcaption>
								</figure>
							</div>
							<p>
								However, the feature maps at the earlier layers may not have such detailed and elaborate features. Instead, the feature maps present at the earlier layers may serve to only extract very simple features such as vertical lines, for example.
							</p>
							<p>
								In implementation, how a CNN works seems to be a black box, with very little true understanding of how the model does what it does. However, by understanding how the feature maps work and visualising them, we can actually break down the inner workings of the CNN, giving us explainability of the model.
							</p>
							<h3>
								Why do we need explainability of CNN models?
							</h3>
							<p>
								The explainability of CNN models in this case is provided by visualising the feature maps of the model.
							</p>
							<p>
								By knowing and seeing which feature maps are activated by a certain image, we can check to see if the model is picking up the correct features, such as in the arched structures example above.	If a model is picking up the wrong features, we have an indication that the accuracy of the model may be low.
							</p>
							<h3>
								How can we understand feature maps?
							</h3>
							<p>
								For us to better understand feature maps and visualise the patterns that significantly activates one, we could:
								<ol>
									<li>Look for specific images which result in a high mean actviation of that particular feature map</li>
									<li>Generate a pattern by optimising pixel values such that a specific feature map is highly activated</li>
								</ol>
								For the purpose of this demo, we will be using the second option to visualise the feature maps of a pre-trained VGG16 model.
							</p>
							<h3>
								Let's visualise some feature maps!
							</h3>	
							<p>
								We shall now generate patterns for various feature maps throughout the convolutional layers of the model, from the earlier layers all the way to the last convolutional layer.
							</p>
							
							<button type="button" class="collapsible">Feature maps from Layer 7</button>
							<div class="collapsible-content">
								<div class="img-showcase">
									<figure>
										<img src="images/layer_7_filter_5.jpg">
									</figure>
									<figure>
										<img src="images/layer_7_filter_8.jpg">
									</figure>
									<figure>
										<img src="images/layer_7_filter_13.jpg">
									</figure>
								</div>

								<div class="img-showcase">
									<figure>
										<img src="images/layer_7_filter_33.jpg">
									</figure>
									<figure>
										<img src="images/layer_7_filter_39.jpg">
									</figure>
									<figure>
										<img src="images/layer_7_filter_54.jpg">
									</figure>
								</div>
							</div>

							<button type="button" class="collapsible">Feature maps from Layer 20</button>
							<div class="collapsible-content">
								<div class="img-showcase">
									<figure>
										<img src="images/layer_20_filter_3.jpg">
									</figure>
									<figure>
										<img src="images/layer_20_filter_5.jpg">
									</figure>
									<figure>
										<img src="images/layer_20_filter_8.jpg">
									</figure>
								</div>

								<div class="img-showcase">
									<figure>
										<img src="images/layer_20_filter_14.jpg">
									</figure>
									<figure>
										<img src="images/layer_20_filter_33.jpg">
									</figure>
									<figure>
										<img src="images/layer_20_filter_38.jpg">
									</figure>
								</div>
							</div>

							<button type="button" class="collapsible">Feature maps from Layer 40</button>
							<div class="collapsible-content">
								<div class="img-showcase">
									<figure>
										<img src="images/layer_40_filter_8.jpg">
									</figure>
									<figure>
										<img src="images/layer_40_filter_12.jpg">
									</figure>
									<figure>
										<img src="images/layer_40_filter_265.jpg">
									</figure>
									
								</div>

								<div class="img-showcase">
									<figure>
										<img src="images/layer_40_filter_45.jpg">
									</figure>
									<figure>
										<img src="images/layer_40_filter_256.jpg">
									</figure>
									<figure>
										<img src="images/layer_40_filter_64.jpg">
									</figure>
								</div>
							</div>

							<h3>
								Notice how some patterns progress deeper into the model?
							</h3>
							<p>
								As we go into the deeper convolutional layers of the model, we can see that the feature maps progress from being simple patterns such as lines, to more complex patterns like shapes, all the way until the patterns seem to resemble recognisable images.
							</p>
							

							<hr class="divider">

							<h3>
								Quiz time!
							</h3>
							<p>
								Let us try to interpret some feature visualisations, and confirm our interpretations.
							</p>

							<!-- <hr class="divider"> -->

							<div class="feature-map-quiz" id="q1">
								<img src="images/q1.jpg">
								<p>1. Click on the image that you think corresponds to the feature map above.</p>
								
								<div class="feature-map-quiz-answers">
									<p></p>
									<p class="ans"><img src="images/dog.jpg"><span>Not quite! The patterns in the feature map seem more reminiscent of a bird with a sharp beak, whereas the dog in this image has a more rounded dog snout.</span></p>
									<p class="ans correct"><img src="images/chicken-crop.JPG"><span>That's right! See the slight resemblance to chicken heads in the feature map?</span></p>
									<p class="ans"><img src="images/bear.jpg"><span>Not quite! The bear in this image has a bear snout, which does not really match the sharp triangular shapes the feature map is looking for.</span></p>
								</div>
							</div>

							<hr class="divider">

							<div class="feature-map-quiz" id="q2">
								<img src="images/q2.jpg">
								<p>2. Click on the image that you think corresponds to the feature map above.</p>
								
								<div class="feature-map-quiz-answers">
									<p></p>
									<p class="ans"><img src="images/basketball.jpg"><span>Hmm, the hexagonal patterns seem to remind me of the panels on a football.</span></p>
									<p class="ans"><img src="images/american-football.jpg"><span>Hmm, the hexagonal patterns seem to remind me of the panels on a football.</span></p>
									<p class="ans correct"><img src="images/football.jpg"><span>Correct, see the hexagonal structures in the feature map?</span></p>
								</div>
							</div>

							<hr class="divider">

							<h3>
								How does this help us?
							</h3>
							<p>
								What we have learnt is that by visualising some of the feature maps, we can make out certain distinct patterns which the model is using for classification.
							</p>
							<p>
								However, we must be careful not to generalise too much here. It does not mean that the hexagonal filter is only responsible for detecting soccer balls. This just means that the filter responds to hexagonal structures, which is most probably used for detecting other objects with such a pattern.
							</p>

							<hr class="divider">

							<h3>
								Let us try to test the hypothesis!
							</h3>
							<p>
								Now, we will try to visualise the most highly activated feature maps for a given image, essentially showing what features the model detects for a given image.
							</p>
							<p>Click on any of the following images to see what feature maps are activated by the model. You may even be able to recognise some!</p>
							<div class="feature-visualise">
								<div class="feature-maps-rows">
									<p class="option" id="feature1"><a href="cnn-explain.html#feature1"><img src="images/butterfly.jpg" class="feature-option"></a></p>
									<p class="option" id="feature2"><a href="cnn-explain.html#feature2"><img src="images/flower.jpg" class="feature-option"></a></p>
									<p class="option" id="feature3"><a href="cnn-explain.html#feature3"><img src="images/tabbycat.jpg" class="feature-option"></a></p>
								</div>
								<div class="visualise feature1">
									<div class="feature-maps">
										<div class="feature-maps-rows">
											<figure><img src="images/butterfly-feature-1.jpg"></figure>
											<figure><img src="images/butterfly-feature-2.jpg"></figure>
											<figure><img src="images/butterfly-feature-3.jpg"></figure>
										</div>
										<div class="feature-maps-rows">
											<figure><img src="images/butterfly-feature-4.jpg"></figure>
											<figure><img src="images/butterfly-feature-5.jpg"></figure>
											<figure><img src="images/butterfly-feature-6.jpg"></figure>
										</div>
									</div>
									<p>Here, we can definitely make out some butterfly patterns from the feature maps, especially the last one.</p>
									<p>Most of the feature maps seem to resemble the shape of the wings, or the patterns on the wings.</p>
								</div>
								<div class="visualise feature2">
									<div class="feature-maps">
										<div class="feature-maps-rows">
											<figure><img src="images/flower-feature-1.jpg"></figure>
											<figure><img src="images/flower-feature-2.jpg"></figure>
										</div>
										<div class="feature-maps-rows">
											<figure><img src="images/flower-feature-3.jpg"></figure>
											<figure><img src="images/flower-feature-4.jpg"></figure>
										</div>
									</div>
									<p>Here, we can definitely make out some form of circular patterns, as well as something resembling flower petals.</p>
								</div>
								<div class="visualise feature3">
									<div class="feature-maps">
										<div class="feature-maps-rows">
											<figure><img src="images/tabbycat-feature-1.jpg"></figure>
											<figure><img src="images/tabbycat-feature-2.jpg"></figure>
										</div>
										<div class="feature-maps-rows">
											<figure><img src="images/tabbycat-feature-3.jpg"></figure>
											<figure><img src="images/tabbycat-feature-4.jpg"></figure>
										</div>
									</div>
									<p>Here, we can distinctly make out the shape of cat's ears in the feature maps.</p>
									<p>There also seems to be some form of cat's fur pattern in the last feature map.</p>
								</div>
							</div>

							<hr class="divider">

							<h3>
								What have we learnt?
							</h3>
							<p>From the two interactive exercises, we are able to visualise and even recognise some patterns from the feature maps. We are able to relate to how CNNs make use of these patterns to classify images.</p>
							<p>However, the patterns present in many other feature maps are not really similar to any pattern that we can recognise. This reinforces that there are still many feature maps which are too abstract for us humans to understand in the same way we recognise patterns. This is merely a way of aiding our understanding of CNN models.</p>
							<!-- <ul class="actions">
								<li><a href="index.html#one" class="button">Back</a></li>
							</ul> -->
							<ul class="actions">
								<li><a href="cnn-basic.html" class="button">Previous</a></li>
								<li><a href="cnn-manipulate.html" class="button">Next</a></li>
							</ul>
						</div>
					</section>

			</div>

		<!-- Footer -->
			<footer id="footer" class="wrapper alt">
				<div class="inner">
					<ul class="menu">
						<li>&copy; Untitled. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

			<!-- Scripts for collapsible sections -->
			<!-- <script> 
				var coll = document.getElementsByClassName("collapsible");
				var i;

				for (i = 0; i < coll.length; i++) {
				coll[i].addEventListener("click", function() {
					this.classList.toggle("active");
					var content = this.nextElementSibling;
					if (content.style.display === "block") {
					content.style.display = "none";
					} else {
					content.style.display = "block";
					}
				});
				}
			</script> -->
			
			<!-- Scripts for collapsible sections -->
			<script>
				var coll = document.getElementsByClassName("collapsible");
				var i;
				
				for (i = 0; i < coll.length; i++) {
				  coll[i].addEventListener("click", function() {
					this.classList.toggle("active");
					var content = this.nextElementSibling;
					if (content.style.maxHeight){
					  content.style.maxHeight = null;
					  content.style.marginBottom = "0em";
					} else {
					  content.style.maxHeight = content.scrollHeight + "px";
					  content.style.marginBottom = "3em";
					} 
				  });
				}
			</script>

			<script>
				$(document).ready(function () {
					$("p.ans").click(function () {
						//Get the id of the div
						var qnum = "#" + $(this).parent().parent().attr("id");
						// Check if the option has been clicked before, and remove the span if yes
						if ($(this).hasClass("right") || $(this).hasClass("wrong")) {
							// window.alert("already clicked")
							$(qnum + " p.ans").removeClass("right wrong");
							$(qnum + " p span").css("display", "none");
							return;
						} 
						//Clear previous freeback:
						$(qnum + " p.ans").removeClass("right wrong");
						$(qnum + " p span").css("display", "none");
						//Apply right or wrong class to p and span.
						var applyclass = "wrong"
						var spancolor = "red"
						if ($(this).hasClass("correct")) {
							applyclass = "right";
							spancolor = "green"
						}
						$(this).addClass(applyclass);
						$(this).children(":nth-child(2)").css("display", "block").css("color", spancolor);
					})
				});
			</script>

			<script>
				$(document).ready(function () {
					$("img.feature-option").click(function () {
						var fnum = $(this).parent().parent().attr('id')
						// Check if the option has been clicked before, and remove the span if yes
						if ($(this).parent().parent().hasClass("select")) {
							$(this).parent().parent().removeClass("select");
							$(this).parent().parent().parent().parent().children(".visualise."+ fnum).css("display", "none");
							return;
						}
						// Clear previous feedback
						$(this).parent().parent().parent().children().removeClass("select");
						$('.visualise').css("display", "none");
						// Show div .visualise.feature# of selected image
						$(this).parent().parent().addClass("select");
						$(this).parent().parent().parent().parent().children(".visualise."+ fnum).css("display", "inline-flex");
					})
				});
			</script>

	</body>
</html>